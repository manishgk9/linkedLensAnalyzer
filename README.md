# ğŸ§  Linkedlence â€“ AI-Powered LinkedIn & Resume Analyzer
# Screen Shots
<p align="center">
  <img width="45%" src="https://github.com/user-attachments/assets/fe19a658-fd56-4d57-8567-b2b83df4069a" />
  <img width="45%" src="https://github.com/user-attachments/assets/63ece164-d28f-4381-8c45-b00eba8ce2eb" />
</p>

<p align="center">
  <img width="50%" src="https://github.com/user-attachments/assets/2f268455-8460-456f-9bae-f701efdf0de5" />
</p>

**Linkedlence** is an 
intelligent AI-driven tool that analyzes LinkedIn profiles and PDF resumes to provide ATS scores, strengths, weaknesses, formatting issues, missing keywords, and actionable suggestions using NLP and Google's Gemini model.

---

## ğŸ¬ Demo Video

[![Watch the video](https://github.com/user-attachments/assets/a63d1231-22c2-4424-8de4-64076282873f)](https://www.youtube.com/watch?v=cXS6Po2JqH0)

---
## ğŸ¯ Features

- ğŸ”— Analyze **LinkedIn profiles** directly using a username
- ğŸ“„ Upload **PDF resumes** and extract data with SpaCy
- ğŸ§  Generate **Gemini-powered analysis** (summary, ATS score, sections)
- ğŸ•µï¸ Data scraping with **Selenium** + **BeautifulSoup**
- ğŸ“¦ Queue processing with **Celery** + **Redis**
- ğŸ¥ **Tailwind-based UI** with responsive design
- ğŸ”§ Debug with `/logs` route and activity logging
- ğŸ” Clean separation of **frontend** and **backend**

---

## ğŸ› ï¸ Tech Stack

| Layer         | Tools / Libraries                                 |
| ------------- | ------------------------------------------------- |
| ğŸ–¥ï¸ Frontend   | React, Redux Toolkit, Tailwind CSS                |
| âš™ï¸ Backend    | FastAPI, Pydantic, SpaCy, Celery, Redis           |
| ğŸ¤– AI/NLP     | Gemini (Google Generative AI), SpaCy              |
| ğŸ•¸ï¸ Scraping   | Selenium (undetected_chromedriver), BeautifulSoup |
| ğŸ“„ Resume     | PDF file processing, NLP-based section extraction |
| ğŸ“¦ Task Queue | Celery, Redis                                     |
| ğŸ“ Logging    | Custom log file viewer via `/logs` endpoint       |

---

## ğŸ“ Project Structure

```bash
linkedlence/
â”‚
â”œâ”€â”€ app/                                # FastAPI backend
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ linkedin_scraper.py         # LinkedIn scraping logic (Selenium + BS4)
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ routes.py                   # API routes: /upload-resume, /analyze-linkedin
â”‚   â”œâ”€â”€ tasks.py                        # Celery task queue management
â”‚   â”œâ”€â”€ gimini/
â”‚   â”‚   â””â”€â”€ gimini_api.py               # Gemini API integration and task handlers
â”‚   â”œâ”€â”€ logs/
â”‚   â”‚   â””â”€â”€ logs.py                     # Scraping and backend logs
â”‚   â”œâ”€â”€ utils/                          # Utility modules
â”‚   â”‚   â”œâ”€â”€ pdf_operation.py           # Resume text extraction and SpaCy processing
â”‚   â”‚   â””â”€â”€ gimin_prompt.py            # Prompt template generation for Gemini
â”‚   â””â”€â”€ main.py                         # FastAPI entrypoint
â”‚
â”œâ”€â”€ frontend/                           # React frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/                 # Reusable UI components
â”‚   â”‚   â”œâ”€â”€ services/                   # Axios or API service calls
â”‚   â”‚   â”œâ”€â”€ redux/                      # Redux slices and async thunks
â”‚   â”‚   â”œâ”€â”€ assets/                     # SVGs, icons, images
â”‚   â”‚   â”œâ”€â”€ AnalyzedResponse.jsx       # Analysis results UI
â”‚   â”‚   â”œâ”€â”€ HomeScreen.jsx             # Upload and input UI
â”‚   â”‚   â””â”€â”€ App.jsx                    # Main React component
â”‚   â”œâ”€â”€ store.jsx                      # Redux store config
â”‚   â””â”€â”€ tailwind.config.js             # TailwindCSS configuration
â”‚
â”œâ”€â”€ .env                                # Environment variables (API keys, etc.)
â”œâ”€â”€ README.md                           # Project documentation (this file)
â”œâ”€â”€ Requirments.txt                     # Python dependencies
```

---

## âš™ï¸ Installation & Setup

### ğŸ“¦ Prerequisites

- Python 3.10+
- Node.js 18+
- Redis server
- Chrome installed (for Selenium)
- Gemini API key (via Google AI Studio)
- Vs Code Editor

---

### ğŸš€ Backend Setup (FastAPI + Celery)

```bash
cd backend
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
pip install -r requirements.txt
```

**Start FastAPI:**

```bash
uvicorn app.main:app --reload
```

**Start Celery Worker:**

```bash
celery -A celery_app worker --loglevel=info
```

**Start Redis (if not running):**

```bash
redis-server
```

---

### ğŸŒ Frontend Setup (React + Tailwind)

```bash
cd frontend
npm install
npm run dev  # or npm start
```

---

## ğŸ”— API Routes

| Endpoint            | Method | Description                                |
| ------------------- | ------ | ------------------------------------------ |
| `/upload-resume`    | POST   | Uploads PDF resume and returns AI analysis |
| `/analyze-linkedin` | POST   | Accepts LinkedIn username and analyzes it  |
| `/logs`             | GET    | Fetches internal scraping/debug logs       |

---

## ğŸ§ª Sample Output

```json
{
  "ats_score": 72,
  "summary": "Entry-level Bootcamp Instructor...",
  "suggestions": ["Add a Certifications section", ...],
  "strengths": ["Quantifiable fitness outcomes", ...],
  "weak_sections": ["Projects section missing", ...],
  "missing_keywords": ["Nutrition Coaching", "Retention"],
  "formatting_issues": ["Inconsistent section titles"],
  "section_scores": {
    "education": 80,
    "experience": 90,
    "skills": 60,
    "projects": 20,
    "certifications": 65,
    "formatting": 30
  }
}
```

---


## ğŸ” Environment Variables

Create a `.env` file in the `backend/` folder with:

```env
OPENAI_API_KEY=your_gemini_key
REDIS_URL=redis://localhost:6379
```

---

## ğŸ§  AI Prompt Logic

The Gemini prompt is structured to:

- Return only valid JSON
- Score resume on ATS metrics
- Suggest improvements and highlight strengths/weaknesses
- Enforce section parsing consistency

Prompt Template: `app/gemini_utils.py`

---

## ğŸ§¹ To Do / Improvements

- [ ] Add authentication / user history
- [ ] Upload .docx support
- [ ] See reports Web Page
- [ ] Graphical chart improvements (Bar chart, Radar chart, etc.)

---

## âš ï¸ Disclaimer & Legal Notice

> **Important**:
> This project is intended **only for educational and non-commercial research purposes**.

- âŒ Do not use this tool to scrape LinkedIn at scale or bypass LinkedInâ€™s terms.
- âœ… This tool does not store any user credentials or personal data.
- âš–ï¸ Respect ethical guidelines while testing scraping logic.
- ğŸ§ª All data shown in demos is anonymized or synthetic.

---

## ğŸ‘¤ Author

**Manish Yadav**

- ğŸ’¼ [LinkedIn](https://www.linkedin.com/in/manishgk9)
- ğŸ¦ [Twitter/X](https://x.com/manishgk9)
- ğŸ’» [GitHub](https://github.com/manishgk9)

> For collaboration, issues, or improvements, feel free to open a PR or contact me!

---

## ğŸ§  Contribution Ideas

- Add resume export as PDF
- Use charts (bar, radar) to display scores
- Add user authentication & dashboards
- Use vector DB for similarity search on resumes

---

## ğŸ“„ License

This project is licensed under the **MIT License**. See [LICENSE](./LICENSE) for more details.

---

> Made with â¤ï¸ using FastAPI, React, and Generative AI.

## ğŸ’¬ Contact

Built with â¤ï¸ by [Manish Yadav](https://github.com/manishgk9)

---
